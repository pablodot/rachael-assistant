# Rachael – docker-compose.yml
# Levanta los servicios del stack local-first.
#
# Servicios activos:
#   memory-db    → PostgreSQL (memoria estructurada)
#   vector-store → Qdrant     (memoria semántica / RAG)
#   llm-runtime  → Ollama / vLLM
#   api-core     → FastAPI orquestador
#   redis        → Cola de tareas arq
#   worker       → arq worker + scheduler proactivo  (Misión 4)
#
# browser-agent corre en el HOST, fuera de Docker (ver SPEC.md §12).

services:

  # ──────────────────────────────────────────────────────────────────────────
  # memory-db — PostgreSQL 16
  # ──────────────────────────────────────────────────────────────────────────
  memory-db:
    build:
      context: ./memory-db
    image: rachael-memory-db:latest
    container_name: rachael-memory-db
    restart: unless-stopped
    environment:
      POSTGRES_DB:       rachael
      POSTGRES_USER:     rachael
      POSTGRES_PASSWORD: rachael
    ports:
      - "5432:5432"
    volumes:
      - memory-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rachael -d rachael"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ──────────────────────────────────────────────────────────────────────────
  # vector-store — Qdrant
  # ──────────────────────────────────────────────────────────────────────────
  vector-store:
    image: qdrant/qdrant:v1.9.4
    container_name: rachael-vector-store
    restart: unless-stopped
    ports:
      - "6333:6333"   # HTTP API / dashboard
      - "6334:6334"   # gRPC
    volumes:
      - vector-store-data:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/6333' 2>/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ──────────────────────────────────────────────────────────────────────────
  # llm-runtime — Ollama
  #
  # Después de levantar, bajar el modelo elegido:
  #   docker exec -it rachael-llm-runtime ollama pull <modelo>
  #
  # LOCAL (6GB VRAM — RTX 3060):
  #   ollama pull qwen2.5:7b                      # ~4.5 GB — recomendado local
  #   ollama pull qwen2.5:7b-instruct-q4_K_M      # ~4.5 GB — instruct explícito
  #   ollama pull mistral:7b-instruct-q4_K_M      # ~4.1 GB — alternativa Mistral
  #
  # SERVIDOR IA (34GB VRAM — 2x 1080Ti + 3060):
  #   ollama pull qwen2.5:32b-instruct-q5_K_M     # ~24 GB  — recomendado servidor
  #   ollama pull qwen2.5:14b-instruct-q6_K       # ~12 GB  — opción intermedia
  #   ollama pull qwen2.5:32b-instruct-q8_0       # ~34 GB  — máxima calidad
  # ──────────────────────────────────────────────────────────────────────────
  llm-runtime:
    image: ollama/ollama:latest
    container_name: rachael-llm-runtime
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - llm-models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ──────────────────────────────────────────────────────────────────────────
  # api-core — FastAPI orquestador
  # ──────────────────────────────────────────────────────────────────────────
  api-core:
    build:
      context: ./api-core
    container_name: rachael-api-core
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://rachael:rachael@memory-db:5432/rachael
      QDRANT_URL:   http://vector-store:6333
      LLM_BASE_URL: http://llm-runtime:11434/v1
      BROWSER_AGENT_URL: http://host.docker.internal:8001
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      memory-db:
        condition: service_healthy
      vector-store:
        condition: service_healthy

  # ──────────────────────────────────────────────────────────────────────────
  # redis — Cola de tareas
  # ──────────────────────────────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    container_name: rachael-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ──────────────────────────────────────────────────────────────────────────
  # worker — arq worker + scheduler proactivo  (Misión 4)
  # ──────────────────────────────────────────────────────────────────────────
  worker:
    build:
      context: ./worker
    image: rachael-worker:latest
    container_name: rachael-worker
    restart: unless-stopped
    environment:
      REDIS_URL:                      redis://redis:6379
      API_CORE_URL:                   http://api-core:8000
      BROWSER_AGENT_URL:              http://host.docker.internal:8001
      LLM_RUNTIME_URL:                http://llm-runtime:11434
      HEALTH_CHECK_EVERY_N_MINUTES:   "5"
      DAILY_BRIEFING_HOUR:            "8"
      DAILY_BRIEFING_MINUTE:          "0"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      api-core:
        condition: service_started

volumes:
  memory-db-data:
  vector-store-data:
  llm-models:

networks:
  default:
    name: rachael-net
